Here is the updated and expanded version with more detail to make the documentation 4–5 pages long:

CP 322 - Final Project

Aditya Chauhan (169027493)

Introduction

In today’s educational landscape, understanding the factors that influence student academic performance is essential for optimizing teaching strategies, resource allocation, and student success. This project employs machine learning techniques to analyze and predict student performance in mathematics and Portuguese, two critical subjects that reflect overall academic development.

The Student Performance Dataset offers a comprehensive look at various factors—ranging from socio-economic backgrounds and parental support to behavioral habits and study routines. By leveraging these factors, this project aims to provide actionable insights into student performance and suggest interventions for at-risk students.

Through detailed data exploration, feature engineering, and the application of advanced machine learning models, we address two key research questions:
	1.	Can external factors such as familial support, alcohol consumption, absences, and others predict a student’s academic success?
	2.	Which machine learning model best predicts student success based on these factors?

The objective is not only to predict grades but also to identify the most influential factors affecting student performance. By answering these questions, we aim to create a predictive framework that supports educators in improving learning outcomes and identifying intervention opportunities.

Dataset Choice

The Student Performance Dataset, sourced from UCI’s Machine Learning Repository, was chosen for its detailed and structured data points. The dataset includes records from 395 students in mathematics (“student-mat.csv”) and 649 students in Portuguese (“student-por.csv”). Both datasets share a similar structure and complement each other, offering a robust foundation for analysis.

Key Features:
	1.	Demographics: Includes age, gender, and address type (urban or rural).
	2.	Family Background: Details parental education levels, family size, and relationships.
	3.	Academic Performance: Captures three grades (G1, G2, G3) across the semester.
	4.	Behavioral Factors: Tracks study time, absences, alcohol consumption, and extracurricular activities.

The dataset is well-suited for supervised learning, providing a mix of numerical and categorical variables. By merging and normalizing the datasets, a unified framework was created for analysis and model training.

Data Exploration

Objective & Use Case

The dataset enables us to identify the key drivers of academic performance and develop predictive models that provide actionable insights. Educators can use these models to:
	•	Identify at-risk students based on behavioral and academic patterns.
	•	Allocate resources like tutoring or counseling to students who need them most.
	•	Monitor and track the effectiveness of intervention strategies over time.

Dataset Overview

The dataset was pre-cleaned and contained no missing values, ensuring a smooth preprocessing pipeline. Some key statistics include:
	•	Age: Ranges from 15 to 22 years, with an average of ~16.7 years.
	•	Absences: Highly variable, ranging from 0 to 75 days, with a mean around 4 days.
	•	Parental Education: Scaled from 0 (none) to 4 (higher education), with a mean of ~2.5, reflecting moderate education levels.

Behavioral Insights:
	1.	Alcohol Consumption:
Students consume more alcohol on weekends (Walc mean ~2.3) than on weekdays (Dalc mean ~1.5).
	2.	Free Time:
Family relationships and free time are rated positively (mean ~3.9 and ~3.2 on a 5-point scale, respectively).
	3.	Study Time:
The average study time is moderate, with a mean score of 2 on a scale of 1–4.

Target Variable (G3)

Final grades (G3) range from 0 to 20, with an average of ~11. The distribution is slightly skewed, with clustering around the mean and occasional outliers.

Correlation Analysis

Correlation matrices revealed:
	•	Strong correlations between G1, G2 (early grades), and G3 (final grade).
	•	Negative correlations between absences, failures, and G3.
	•	Behavioral factors like going out and alcohol consumption showed weaker but noticeable correlations with performance.

Experimental Design & Preprocessing

Data Cleaning

The two datasets were merged into a single unified dataset containing 1,044 students. The preprocessing pipeline involved encoding categorical variables, normalizing numerical features, and removing duplicates. Since the dataset had no missing values, this process was streamlined.

Feature Engineering

To extract deeper insights and improve model performance, the following new features were engineered:
	1.	Parental Education Average: Combined Medu (mother’s education) and Fedu (father’s education) into a single feature to capture overall parental education levels.
	2.	Absenteeism Ratio: Created a normalized feature to analyze the impact of absences relative to health and study time.
	3.	Social Activity Score: Derived from the ratio of time spent going out to free time available.
	4.	Performance Progression: Calculated the difference between G2 and G1 grades to observe trends over the semester.

Normalization and Encoding

Categorical variables such as school type, address, and family support were one-hot encoded for compatibility with machine learning models. Numerical features, such as grades and absences, were normalized using MinMaxScaler to standardize their scales and improve model performance.

Train-Test Split

The dataset was divided into training (70%), validation (15%), and testing (15%) subsets. Stratified sampling ensured that the distribution of G3 grades remained consistent across subsets.

Model Implementation & Comparisons

To address the research questions, multiple machine learning models were implemented and compared. Each model was evaluated based on its ability to accurately predict G3 grades.

Implemented Models
	1.	Linear Regression: A baseline model for comparison.
	2.	k-Nearest Neighbors (k-NN): Explores non-linear relationships between features.
	3.	Support Vector Machines (SVM): Utilized with a radial kernel for better performance.
	4.	Decision Tree Regressor: Captures complex feature interactions but tends to overfit.
	5.	Random Forest Regressor: Combines multiple decision trees for enhanced accuracy.
	6.	Neural Networks: Includes Multi-Layer Perceptron (MLP) and GRU (Gated Recurrent Unit).

Model Evaluation

Performance Metrics:
	•	Mean Squared Error (MSE): Measures the average squared error between predictions and actual values.
	•	Root Mean Squared Error (RMSE): Provides an interpretable metric in the same units as G3.
	•	R² Score: Assesses the proportion of variance in the target variable explained by the model.

Selected Model: ANN (GRU)

The Gated Recurrent Unit (GRU) model emerged as the selected model. Unlike traditional machine learning models, GRUs are designed to handle sequential data effectively. While this dataset is primarily tabular, the temporal relationship between grades (G1, G2, G3) and progression trends makes GRUs a viable choice.

Performance Metrics:
	•	MSE: 0.0360
	•	MAE: 0.1340
	•	RMSE: 0.1899
	•	R²: 0.0009

The GRU model’s performance, while not optimal, reflects the potential of advanced architectures in educational datasets.

Feature Importance

Permutation-based feature importance analysis revealed that:
	1.	Fjob_binary_1 (father’s job): A significant contributor to the predictions.
	2.	Absenteeism_vs_Health: Indicates the critical impact of absences relative to health factors.
	3.	Parental_Education_Avg: Highlights the influence of overall parental education levels.

Interestingly, the model placed minimal emphasis on traditional predictors such as absences and failures, instead favoring engineered features like absenteeism ratios.

Conclusion

The ANN (GRU) model was selected for its innovative architecture and ability to model sequential dependencies. However, its moderate performance metrics indicate room for improvement, especially in feature engineering and dataset suitability.

Future Directions
	1.	Enhance Feature Engineering:
Explore features better suited for sequential models, such as time-series representations of grades or study habits.
	2.	Hybrid Models:
Combine GRU with traditional tabular-focused architectures to balance temporal and non-temporal feature modeling.
	3.	Expand Dataset:
Incorporate more schools, subjects, and demographic diversity to improve generalizability.
	4.	Advanced Optimization:
Experiment with hyperparameter tuning and dropout layers to reduce overfitting in the GRU model.

This project underscores the importance of feature selection and model choice in educational data science, paving the way for future innovations in predictive analytics for student success.