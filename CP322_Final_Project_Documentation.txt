CP 322 - Final Project

Aditya Chauhan (169027493)

Introduction

In today’s educational landscape, understanding the factors that influence student academic performance is essential for optimizing teaching strategies, resource allocation, and student success. This project uses machine learning techniques to analyze and predict student performance in mathematics and Portuguese, two critical subjects that reflect overall academic development.

The Student Performance Dataset offers a comprehensive look at various factors—ranging from socio-economic backgrounds and parental support to behavioral habits and study routines. By leveraging these factors, this project aims to provide actionable insights into student performance and suggest interventions for at-risk students.

Through detailed analysis, feature engineering, and the application of advanced machine learning models, we address two key research questions:
	1.	Can external factors such as familial support, alcohol consumption, absences, and others predict a student’s academic success?
	2.	Which machine learning model best predicts student success based on these factors?

By answering these questions, we aim to create a predictive framework that supports educators in improving learning outcomes.

Dataset Choice

The Student Performance Dataset, sourced from UCI’s machine learning repository, was selected for its detailed and structured data points. It includes records from 395 students in mathematics (“student-mat.csv”) and 649 students in Portuguese (“student-por.csv”). Both datasets are complementary, providing a robust foundation for analysis.

Key Features:
	1.	Demographics: Includes age, gender, and address type (urban or rural).
	2.	Family Background: Details parental education levels, family size, and relationships.
	3.	Academic Performance: Captures three grades (G1, G2, G3) across the semester.
	4.	Behavioral Factors: Tracks study time, absences, alcohol consumption, and extracurricular activities.

The data is well-suited for supervised learning, offering a mix of numerical and categorical variables. By merging and normalizing the datasets, we can create a unified framework for analysis.

Data Exploration

Objective & Use Case
The dataset enables us to identify the key drivers of academic performance and develop predictive models that provide actionable insights. For example, educators can use this model to:
	•	Pinpoint at-risk students based on behavioral patterns.
	•	Allocate resources, such as tutoring or counseling, to students who need them most.
	•	Track the effectiveness of interventions over time.

Dataset Overview
The datasets contain no missing values, ensuring a seamless preprocessing pipeline. Here are some key statistics:
	•	Age: Ranges from 15 to 22 years, with a mean of ~16.7.
	•	Absences: Highly variable, ranging from 0 to 75 days in the math dataset.
	•	Parental Education: Scaled from 0 to 4, with a mean of ~2.5, reflecting moderate education levels.

Behavioral Insights:
	1.	Alcohol consumption is higher on weekends than on weekdays (mean Walc ~2.3, Dalc ~1.5).
	2.	Family relationships and free time are rated positively (mean ~3.9 and ~3.2, respectively).
	3.	Study time averages 2 (on a 1-4 scale), indicating moderate dedication.

Target Variable (G3)
Final grades (G3) range from 0 to 20, with a mean of ~11. The distribution shows clustering around the mean, with occasional outliers.

Correlation Analysis
Correlation matrices reveal that:
	•	G1 and G2 (early grades) have the strongest correlation with G3.
	•	Absences and failures negatively impact G3, as expected.
	•	Behavioral factors like going out and alcohol consumption show weaker but noticeable correlations.

Feature Analysis

To better understand the dataset, we categorized the features into continuous and categorical types. Each type offers unique insights into student behavior and academic performance.

Continuous Features
	1.	Age: Represents typical high school demographics, with consistency across both datasets.
	2.	Travel Time: Indicates most students live close to school (mean ~1.5).
	3.	Study Time: Moderate dedication is observed, with room for improvement.
	4.	Absences: A critical feature, with higher absences correlating to lower grades.

Categorical Features
	1.	Family Size: Two categories—GT3 (greater than three members) is the most common.
	2.	Parental Education: Captures the educational background of both parents on a 0-4 scale.
	3.	Extracurricular Activities: Slightly more students participate than not, indicating a balanced student population.
	4.	Romantic Relationships: Most students are not in a relationship, a potential factor influencing free time and focus.

Experimental Design & Preprocessing

Data Cleaning
The two datasets were merged into a single unified dataset of 1,044 students. Cleaning involved encoding categorical variables, normalizing numerical features, and removing duplicates. No missing values ensured a streamlined process.

Feature Engineering
	1.	Parental Education Average:

Combined Medu and Fedu into a single feature representing overall parental education levels.
2. Absenteeism Ratio: Created a normalized feature to analyze the impact of absences relative to health and study time.
3. Social Activity Score: Derived from the ratio of time spent going out to free time available.
4. Performance Progression: Calculated the difference between G2 and G1 grades to observe trends over the semester.

Normalization and Encoding
Categorical variables such as school type, address, and family support were one-hot encoded to ensure compatibility with machine learning models. Numerical features, such as grades and absences, were normalized using MinMaxScaler to standardize their scales and improve model performance.

Train-Test Split
The dataset was split into training (70%), validation (15%), and testing (15%) subsets to ensure robust evaluation. Stratification was applied to preserve the distribution of G3 grades across subsets.

Model Implementation & Comparisons

To address the research questions, we implemented a variety of machine learning models. Each model was tuned and evaluated based on its ability to predict G3 grades accurately.

Implemented Models
	1.	Linear Regression: A baseline model for comparison.
	2.	k-Nearest Neighbors (k-NN): Explores non-linear relationships between features.
	3.	Support Vector Machines (SVM): Utilized with a radial kernel for better performance.
	4.	Decision Tree Regressor: Captures complex feature interactions.
	5.	Random Forest Regressor: Combines multiple decision trees for enhanced accuracy.
	6.	Neural Networks: Includes Multi-Layer Perceptron (MLP) and Feedforward Neural Networks (FNN).

Hyperparameter Tuning
Each model underwent grid search optimization to identify the best parameters. For example:
	•	Random Forest: Tuned the number of trees, max depth, and minimum samples per split.
	•	SVM: Adjusted kernel type, regularization parameter (C), and gamma.

Model Evaluation

Performance Metrics
Key evaluation metrics included:
	1.	Mean Squared Error (MSE): Measures the average squared error between predictions and actual values.
	2.	Root Mean Squared Error (RMSE): Provides an interpretable metric in the same units as G3.
	3.	R² Score: Assesses the proportion of variance explained by the model.

Results
	•	Random Forest Regressor delivered the best performance:
	•	MSE: 0.0036
	•	RMSE: 0.0601
	•	R²: 0.8998

Other models, such as k-NN and SVM, performed reasonably well but lacked the generalization capabilities of Random Forest. Neural networks showed potential but required more data and computational resources for optimization.

Feature Importance
Random Forest’s feature importance analysis revealed:
	•	G1 and G2 grades were the most significant predictors of G3.
	•	Absences, parental education, and study time contributed moderately.
	•	Behavioral factors, such as alcohol consumption, had a minimal impact.

Residual Analysis
Residuals for Random Forest were normally distributed and centered around zero, indicating unbiased predictions and no systematic errors.

Conclusion

The Random Forest Regressor emerged as the best model for predicting student grades, achieving high accuracy and robustness. The analysis highlights the importance of early performance (G1, G2) and absenteeism as key factors influencing final grades (G3). Behavioral factors, though less impactful, still provide valuable context.

Key Insights
	1.	Early intervention for students with poor initial grades can improve final outcomes.
	2.	Addressing absenteeism is crucial for enhancing overall performance.
	3.	Parental education levels correlate with academic success, suggesting that family involvement plays a significant role.

Future Directions
	•	Explore additional features, such as extracurricular activities and mental health data.
	•	Test ensemble methods combining Random Forest with neural networks for improved accuracy.
	•	Expand the dataset to include more schools and subjects, ensuring broader applicability.