{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP 322 - Final Project\n",
    "\n",
    "Aditya Chauhan (169027493)\n",
    "\n",
    "### Dataset Choice\n",
    "\n",
    "- [Student Performance Dataset](https://archive.ics.uci.edu/dataset/320/student+performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read/Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students in merged dataset: 382\n",
      "Merged dataset saved to 'student-merged.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "student_mat = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "student_por = pd.read_csv(\"student-por.csv\", sep=\";\")\n",
    "\n",
    "# Merge datasets on specified columns\n",
    "merge_columns = [\n",
    "    \"school\", \"sex\", \"age\", \"address\", \"famsize\", \"Pstatus\", \n",
    "    \"Medu\", \"Fedu\", \"Mjob\", \"Fjob\", \"reason\", \"nursery\", \"internet\"\n",
    "]\n",
    "merged_data = pd.merge(student_mat, student_por, on=merge_columns, suffixes=('_mat', '_por'))\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_data.to_csv(\"student-merged.csv\", index=False)\n",
    "print(\"Number of students in merged dataset:\", merged_data.shape[0])\n",
    "print(\"Merged dataset saved to 'student-merged.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized column names:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'pstatus', 'medu', 'fedu', 'mjob', 'fjob', 'reason', 'nursery', 'internet', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'higher', 'romantic', 'famrel', 'freetime', 'goout', 'dalc', 'walc', 'health', 'absences', 'g1', 'g2', 'g3']\n",
      "Number of duplicate rows: 12\n",
      "Shape after removing duplicates: (370, 33)\n",
      "Shape after removing invalid entries: (370, 33)\n",
      "Shape after consolidating redundant features: (370, 33)\n",
      "Unique values in 'school': ['GP' 'MS']\n",
      "Final dataset shape: (323, 33)\n",
      "Sample data after cleaning:\n",
      "  school sex  age address famsize pstatus  medu  fedu     mjob      fjob  ...  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
      "\n",
      "  famrel freetime goout dalc  walc  health  absences  g1  g2  g3  \n",
      "0      4        3     4    1     1       3         6   5   6   6  \n",
      "1      5        3     3    1     1       3         4   5   5   6  \n",
      "2      4        3     2    2     3       3        10   7   8  10  \n",
      "3      3        2     2    1     1       5         2  15  14  15  \n",
      "4      4        3     2    1     2       5         4   6  10  10  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Cleaned dataset saved to 'student-merged-cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Resolve Duplicate Columns\n",
    "columns_to_keep = [\n",
    "    'school', 'sex', 'age', 'address', 'famsize', 'Pstatus', \n",
    "    'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'nursery', 'internet',\n",
    "    'guardian_mat', 'traveltime_mat', 'studytime_mat', 'failures_mat', 'schoolsup_mat', \n",
    "    'famsup_mat', 'paid_mat', 'activities_mat', 'higher_mat', 'romantic_mat', \n",
    "    'famrel_mat', 'freetime_mat', 'goout_mat', 'Dalc_mat', 'Walc_mat', 'health_mat', \n",
    "    'absences_mat', 'G1_mat', 'G2_mat', 'G3_mat'\n",
    "]\n",
    "\n",
    "# Retain the '_mat' versions and rename columns to remove suffix\n",
    "merged_data = merged_data[columns_to_keep]\n",
    "merged_data.columns = [col.replace('_mat', '') for col in merged_data.columns]\n",
    "\n",
    "# Standardize Column Names\n",
    "merged_data.columns = merged_data.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('-', '_')\n",
    "print(\"Standardized column names:\")\n",
    "print(merged_data.columns.tolist())\n",
    "\n",
    "# Handle Missing Values\n",
    "# Fill numeric columns with the median\n",
    "numeric_columns = merged_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "merged_data[numeric_columns] = merged_data[numeric_columns].fillna(merged_data[numeric_columns].median())\n",
    "\n",
    "# Fill categorical columns with the mode\n",
    "categorical_columns = merged_data.select_dtypes(include=['object']).columns\n",
    "merged_data[categorical_columns] = merged_data[categorical_columns].fillna(merged_data[categorical_columns].mode().iloc[0])\n",
    "\n",
    "# Remove Duplicates\n",
    "duplicates = merged_data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "merged_data.drop_duplicates(inplace=True)\n",
    "print(f\"Shape after removing duplicates: {merged_data.shape}\")\n",
    "\n",
    "# Remove Invalid Entries\n",
    "# Remove invalid or implausible entries for age and G3\n",
    "merged_data = merged_data[(merged_data['age'] >= 15) & (merged_data['age'] <= 22)]\n",
    "merged_data = merged_data[(merged_data['g3'] >= 0) & (merged_data['g3'] <= 20)]\n",
    "print(\"Shape after removing invalid entries:\", merged_data.shape)\n",
    "\n",
    "# Consolidate Redundant Features\n",
    "# Combine guardian_mat and guardian_por (if both exist)\n",
    "if 'guardian_mat' in merged_data.columns and 'guardian_por' in merged_data.columns:\n",
    "    merged_data['guardian'] = merged_data[['guardian_mat', 'guardian_por']].mode(axis=1)[0]\n",
    "    merged_data.drop(columns=['guardian_mat', 'guardian_por'], inplace=True)\n",
    "\n",
    "print(\"Shape after consolidating redundant features:\", merged_data.shape)\n",
    "\n",
    "# Validate Data Consistency\n",
    "# Standardize categorical values\n",
    "if 'school' in merged_data.columns:\n",
    "    print(\"Unique values in 'school':\", merged_data['school'].unique())\n",
    "    merged_data['school'] = merged_data['school'].str.upper()\n",
    "\n",
    "# Remove Outliers\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "columns_to_check = ['absences', 'g1', 'g2', 'g3']\n",
    "for col in columns_to_check:\n",
    "    merged_data = remove_outliers(merged_data, col)\n",
    "\n",
    "# Verify Final Dataset\n",
    "print(\"Final dataset shape:\", merged_data.shape)\n",
    "print(\"Sample data after cleaning:\")\n",
    "print(merged_data.head())\n",
    "\n",
    "# Save the Cleaned Dataset\n",
    "merged_data.to_csv(\"student-merged-cleaned.csv\", index=False)\n",
    "print(\"Cleaned dataset saved to 'student-merged-cleaned.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived/Created Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data with new features:\n",
      "   avg_early_grades  parental_education  total_alcohol  high_absences  \\\n",
      "0               5.5                 4.0              2              1   \n",
      "1               5.0                 1.0              2              0   \n",
      "2               7.5                 1.0              5              1   \n",
      "3              14.5                 3.0              2              0   \n",
      "4               8.0                 3.0              3              0   \n",
      "\n",
      "   failure_study_ratio  grade_improvement  alc_ratio  \n",
      "0                  0.0                  1        0.5  \n",
      "1                  0.0                  0        0.5  \n",
      "2                  1.0                  1        1.0  \n",
      "3                  0.0                 -1        0.5  \n",
      "4                  0.0                  4        1.0  \n"
     ]
    }
   ],
   "source": [
    "# Derived/Created Features\n",
    "\n",
    "# 1. Average Early Grades (G1 and G2)\n",
    "merged_data['avg_early_grades'] = (merged_data['g1'] + merged_data['g2']) / 2\n",
    "\n",
    "# 2. Combined Parental Education\n",
    "merged_data['parental_education'] = (merged_data['medu'] + merged_data['fedu']) / 2\n",
    "\n",
    "# 3. Total Alcohol Consumption\n",
    "merged_data['total_alcohol'] = merged_data['dalc'] + merged_data['walc']\n",
    "\n",
    "# 4. High Absenteeism\n",
    "median_absences = merged_data['absences'].median()\n",
    "merged_data['high_absences'] = merged_data['absences'].apply(lambda x: 1 if x > median_absences else 0)\n",
    "\n",
    "# 5. Failures Weighted by Study Time\n",
    "merged_data['failure_study_ratio'] = merged_data['failures'] / (merged_data['studytime'] + 1)\n",
    "\n",
    "# 6. Early Grade Improvement\n",
    "merged_data['grade_improvement'] = merged_data['g2'] - merged_data['g1']\n",
    "\n",
    "# 7. Weekend vs Weekday Alcohol Ratio\n",
    "merged_data['alc_ratio'] = merged_data['walc'] / (merged_data['dalc'] + 1)\n",
    "\n",
    "# Verify the new features\n",
    "print(\"Sample data with new features:\")\n",
    "print(merged_data[['avg_early_grades', 'parental_education', 'total_alcohol', 'high_absences', \n",
    "                   'failure_study_ratio', 'grade_improvement', 'alc_ratio']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Score Normalized Data Sample:\n",
      "  school sex       age address famsize pstatus      medu      fedu     mjob  \\\n",
      "0     GP   F  1.275153       U     GT3       A  1.082413  1.321009  at_home   \n",
      "1     GP   F  0.417081       U     GT3       T -1.670495 -1.455689  at_home   \n",
      "2     GP   F -1.299063       U     LE3       T -1.670495 -1.455689  at_home   \n",
      "3     GP   F -1.299063       U     GT3       T  1.082413 -0.530123   health   \n",
      "4     GP   F -0.440991       U     GT3       T  0.164777  0.395443    other   \n",
      "\n",
      "       fjob  ...        g1        g2        g3 avg_early_grades  \\\n",
      "0   teacher  ... -1.934116 -1.704848 -1.730933        -1.865749   \n",
      "1     other  ... -1.934116 -2.019695 -1.730933        -2.025346   \n",
      "2     other  ... -1.317718 -1.075156 -0.495372        -1.227363   \n",
      "3  services  ...  1.147875  0.813921  1.049079         1.006991   \n",
      "4     other  ... -1.625917 -0.445464 -0.495372        -1.067766   \n",
      "\n",
      "   parental_education  total_alcohol  high_absences failure_study_ratio  \\\n",
      "0            1.332032      -0.894846       1.258571           -0.320214   \n",
      "1           -1.733856      -0.894846      -0.794552           -0.320214   \n",
      "2           -1.733856       0.582336       1.258571            3.541483   \n",
      "3            0.310069      -0.894846      -0.794552           -0.320214   \n",
      "4            0.310069      -0.402452      -0.794552           -0.320214   \n",
      "\n",
      "  grade_improvement alc_ratio  \n",
      "0          0.613007 -0.946488  \n",
      "1         -0.099228 -0.946488  \n",
      "2          0.613007  0.170758  \n",
      "3         -0.811463 -0.946488  \n",
      "4          2.749713  0.170758  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "Robust Scaled Data Sample:\n",
      "  school sex  age address famsize pstatus  medu  fedu     mjob      fjob  ...  \\\n",
      "0     GP   F  2.0       U     GT3       A   0.5   0.5  at_home   teacher  ...   \n",
      "1     GP   F  1.0       U     GT3       T  -1.0  -1.0  at_home     other  ...   \n",
      "2     GP   F -1.0       U     LE3       T  -1.0  -1.0  at_home     other  ...   \n",
      "3     GP   F -1.0       U     GT3       T   0.5  -0.5   health  services  ...   \n",
      "4     GP   F  0.0       U     GT3       T   0.0   0.0    other     other  ...   \n",
      "\n",
      "    g1   g2    g3 avg_early_grades  parental_education  total_alcohol  \\\n",
      "0 -1.2 -1.0 -1.25        -1.222222            0.666667      -0.333333   \n",
      "1 -1.2 -1.2 -1.25        -1.333333           -1.333333      -0.333333   \n",
      "2 -0.8 -0.6 -0.25        -0.777778           -1.333333       0.666667   \n",
      "3  0.8  0.6  1.00         0.777778            0.000000      -0.333333   \n",
      "4 -1.0 -0.2 -0.25        -0.666667            0.000000       0.000000   \n",
      "\n",
      "   high_absences failure_study_ratio grade_improvement alc_ratio  \n",
      "0            1.0                 0.0               0.5      -1.0  \n",
      "1            0.0                 0.0               0.0      -1.0  \n",
      "2            1.0                 1.0               0.5       0.0  \n",
      "3            0.0                 0.0              -0.5      -1.0  \n",
      "4            0.0                 0.0               2.0       0.0  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "Preprocessed datasets saved:\n",
      "- Z-Score Normalized Dataset: 'student-zscore-normalized.csv'\n",
      "- Robust Scaled Dataset: 'student-robust-scaled.csv'\n"
     ]
    }
   ],
   "source": [
    "# Select numeric columns\n",
    "numeric_columns = merged_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Create pipelines for both scaling methods\n",
    "def preprocess_data(data, scaler):\n",
    "    \"\"\"\n",
    "    Function to preprocess data using the specified scaler.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pandas DataFrame, the dataset to scale.\n",
    "    - scaler: Scikit-learn scaler object (e.g., StandardScaler, RobustScaler).\n",
    "    \n",
    "    Returns:\n",
    "    - scaled_data: pandas DataFrame, the scaled dataset.\n",
    "    \"\"\"\n",
    "    scaled_data = data.copy()\n",
    "    scaled_data[numeric_columns] = scaler.fit_transform(scaled_data[numeric_columns])\n",
    "    return scaled_data\n",
    "\n",
    "# Preprocess using Z-Score Normalization\n",
    "zscore_scaler = StandardScaler()\n",
    "zscore_data = preprocess_data(merged_data, zscore_scaler)\n",
    "print(\"Z-Score Normalized Data Sample:\")\n",
    "print(zscore_data.head())\n",
    "\n",
    "# Preprocess using Robust Scaling\n",
    "robust_scaler = RobustScaler()\n",
    "robust_data = preprocess_data(merged_data, robust_scaler)\n",
    "print(\"Robust Scaled Data Sample:\")\n",
    "print(robust_data.head())\n",
    "\n",
    "# Save preprocessed datasets for future use\n",
    "zscore_data.to_csv(\"student-zscore-normalized.csv\", index=False)\n",
    "robust_data.to_csv(\"student-robust-scaled.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessed datasets saved:\")\n",
    "print(\"- Z-Score Normalized Dataset: 'student-zscore-normalized.csv'\")\n",
    "print(\"- Robust Scaled Dataset: 'student-robust-scaled.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
