# Documentation for CP-322 Final Project

## Overview
This document provides a detailed explanation of the data processing, feature engineering, and normalization pipelines implemented as part of the CP-322 final project. These steps ensure the dataset is clean, well-structured, and ready for exploratory data analysis and machine learning modeling.

---

## 1. Data Cleaning
### Steps:
1. **Resolve Duplicate Columns:**
   - Retained the `'_mat'` suffix versions of features and renamed columns to remove the suffix.

2. **Standardize Column Names:**
   - All column names were converted to lowercase and any special characters or spaces were replaced with underscores for consistency.

3. **Handle Missing Values:**
   - Numeric columns were filled with the median value.
   - Categorical columns were filled with the mode value.

4. **Remove Duplicates:**
   - Identified and removed duplicate rows from the dataset.

5. **Remove Invalid Entries:**
   - Removed rows where `age` was outside the range of 15 to 22.
   - Ensured `G3` values were within the valid range of 0 to 20.

6. **Consolidate Redundant Features:**
   - Combined similar columns such as `guardian_mat` and `guardian_por` into a single column.

7. **Validate Data Consistency:**
   - Standardized categorical features like `school` to ensure consistent formatting.

8. **Remove Outliers:**
   - Applied the IQR method to remove outliers in numeric columns like `absences`, `G1`, `G2`, and `G3`.

---

## 2. Feature Engineering
### Created/Derived Features:
1. **`avg_early_grades`**:
   - Average of `G1` and `G2` to represent overall early academic performance.

2. **`parental_education`**:
   - Combined `Medu` and `Fedu` to represent average parental education level.

3. **`total_alcohol`**:
   - Sum of `Dalc` and `Walc` to quantify total alcohol consumption.

4. **`high_absences`**:
   - Binary feature indicating whether `absences` exceeded the median value.

5. **`failure_study_ratio`**:
   - Ratio of `failures` to `studytime` to evaluate study efficiency.

6. **`grade_improvement`**:
   - Difference between `G2` and `G1` to measure performance trends.

7. **`alc_ratio`**:
   - Ratio of weekend to weekday alcohol consumption.

---

## 3. Normalization Pipelines
Two normalization methods were implemented to prepare the dataset for machine learning models:

### **1. Z-Score Normalization**
- Standardizes numeric features by centering them around a mean of `0` and scaling to a standard deviation of `1`.
- Ideal for distance-based algorithms and when features have different units.

### **2. Robust Scaling**
- Scales features using the median and interquartile range (IQR), reducing the influence of outliers.
- Suitable for datasets with significant outliers.

### Implementation:
1. A preprocessing function, `preprocess_data()`, was created to apply the scalers to numeric columns.
2. Two datasets were generated:
   - **Z-Score Normalized Dataset:** Saved as `student-zscore-normalized.csv`.
   - **Robust Scaled Dataset:** Saved as `student-robust-scaled.csv`.

---

## 4. Saved Files
1. **`student-merged-cleaned.csv`**:
   - Cleaned dataset after removing duplicates, outliers, and invalid entries.

2. **`student-zscore-normalized.csv`**:
   - Dataset with Z-Score normalization applied.

3. **`student-robust-scaled.csv`**:
   - Dataset with Robust Scaling applied.

---

## Next Steps
1. **Exploratory Data Analysis (EDA):**
   - Analyze the relationships between features and the target variable (`G3`).
   - Visualize feature distributions and correlations.

2. **Model Implementation:**
   - Train multiple machine learning models using both Z-Score Normalized and Robust Scaled datasets.
   - Compare model performance metrics (accuracy, F1-score, etc.) to select the best preprocessing method.

3. **Feature Selection:**
   - Use insights from EDA and model performance to refine feature selection.

---